### integration
#### comparison
train: bts_main <-> trainer (loaded from main)
model: <-> model 
loss: bts_ldu <-> 
        loss_sup:CE; loss_sup_SubCls; loss_unsup_SubCls; loss_unsup_reg 
        没有def的function 直接one-liner计算了          

### differences between models
#### in `forward` 
    note: if not training  = inference or eval
Test: 
    phase: inference 
    returns: segmentation output `output_l` for the input `x_l`
Save_Features: 
    phase: inference 
    returns: intermediate feature maps `feat` (latent code, output of encoder) and  `output_l` 
BaseLine
    phase: inference & training
    training mode: supervised
    encode and classify (i.e. decode with one-layer)
USRN
    phase: inference & training
    training mode: supervised & semi

#### for models in training mode
`curr_losses` and `outputs`: Python dictionaries that contains the losses and predictions, respectively, computed during the forward pass of the model

#### Process
Forward Pass
    Encode: 
        output feature maps `feat`
        DeepLab or psp backbone
    Classification: 
        converts the features extracted by the encoder into class scores (logits) for each pixel. classifier: a fully connected layer
    Interpolation (if downsample): 
        F.interpolate upsample the logits (class scores) generated by the classifier to match the original input image size, which is usually the functionality of the decoder
        DOES NOT serve as decoder in this case. this model does not have a decoder
    Prediction: generate pseudo-labels
        normalize logits with an activation function (in this case softmax) to obtain probabilities, then take the max probability as pseudo-label
Loss Calculation
Backpropogation
Parameter Update
Iteration

### modifications
- model.py
- in config of voc_1over32_usrn, change the dataloader into normal_kmeans
